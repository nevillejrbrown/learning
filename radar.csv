name,ring,quadrant,isNew,description
Applying product management to internal platforms,Adopt,Techniques,FALSE,"<p>More and more companies are building internal platforms to roll out new digital solutions quickly and efficiently. Companies that succeed with this strategy are <strong>applying product management to internal platforms</strong>. This means establishing empathy with internal consumers (the development teams) and collaborating with them on the design. Platform product managers create roadmaps and ensure the platform delivers value to the business and enhances the developer experience. Unfortunately, we're also seeing less successful approaches, where teams create a platform in the void, based on unverified assumptions and without internal customers. These platforms, often despite aggressive internal tactics, end up being underutilized and a drain on the organization's delivery capability. As usual, good product management is all about building products that consumers love.</p>"
Infrastructure as code,Adopt,Techniques,FALSE,"<p>Although <strong>infrastructure as code</strong> is a relatively old technique (we’ve featured it in the Radar in 2011), it has become vitally important in the modern cloud era where the act of setting up infrastructure has become the passing of configuration instructions to a cloud platform. When we say ""as code"" we mean that all the good practices we've learned in the software world should be applied to infrastructure. Using source control, adhering to the <a href=""https://en.wikipedia.org/wiki/Don%27t_repeat_yourself"">DRY principle</a>, modularization, maintainability, and using automated testing and deployment are all critical practices. Those of us with a deep software and infrastructure background need to empathize with and support colleagues who do not. Saying ""treat infrastructure like code"" isn't enough; we need to ensure the hard-won learnings from the software world are also applied consistently throughout the infrastructure realm.</p>"
Micro frontends,Adopt,Techniques,FALSE,"<p>We've seen significant benefits from introducing <a href=""https://martinfowler.com/articles/microservices.html"">microservices</a>, which have allowed teams to scale the delivery of independently deployed and maintained services. Unfortunately, we've also seen many teams create a front-end monolith — a large, entangled browser application that sits on top of the back-end services — largely neutralizing the benefits of microservices. <strong>Micro frontends</strong> have continued to gain in popularity since they were first introduced. We've seen many teams adopt some form of this architecture as a way to manage the complexity of multiple developers and teams contributing to the same user experience. In June of last year, one of the originators of this technique published an <a href=""https://martinfowler.com/articles/micro-frontends.html"">introductory article</a> that serves as a reference for micro frontends. It shows how this style can be implemented using various web programming mechanisms and builds out an example application using <a href=""/radar/languages-and-frameworks/react-js"">React.js</a>. We're confident this style will grow in popularity as larger organizations try to decompose UI development across multiple teams.</p>"
Pipelines as code,Adopt,Techniques,FALSE,"<p>The <strong>pipelines as code</strong> technique emphasizes that the configuration of delivery pipelines that build, test and deploy our applications or infrastructure should be treated as code; they should be placed under source control and modularized in reusable components with automated testing and deployment. As organizations move to decentralized autonomous teams building <a href=""https://martinfowler.com/articles/microservices.html"">microservices</a> or <a href=""/radar/techniques/micro-frontends"">micro frontends</a>, the need for engineering practices in managing pipelines as code increases to keep building and deploying software consistent within the organization. This need has given rise to delivery pipeline templates and tooling that enable a standardized way to build and deploy services and applications. Such tools use the <em>declarative delivery pipelines</em> of applications, adopting a pipeline blueprint to execute the underlying tasks for various stages of a delivery lifecycle such as build, test and deployment; and they abstract away implementation details. The ability to build, test and deploy pipelines as code should be one of the evaluation criteria for choosing a CI/CD tool.</p>"
Pragmatic remote pairing,Adopt,Techniques,TRUE,"<p>We firmly believe that <a href=""https://martinfowler.com/articles/on-pair-programming.html"">pair programming</a> improves the quality of code, spreads knowledge throughout a team and allows overall faster delivery of software. In a post COVID-19 world, however, many software teams will be distributed or fully remote, and in this situation we recommend <strong>pragmatic remote pairing</strong>: adjusting pairing practices to what's possible given the tools at hand. Consider tools such as <a href=""/radar/tools/visual-studio-live-share"">Visual Studio Live Share</a> for efficient, low-latency collaboration. Only resort to pixel-sharing if both participants reside in relative geographic proximity and have high-bandwidth internet connections. Pair developers who are in similar time zones rather than expecting pairing to work between participants regardless of their location. If pairing isn't working for logistical reasons, fall back to practices such as individual programming augmented via code reviews, pull-request collaboration (but beware <a href=""/radar/techniques/long-lived-branches-with-gitflow"">long-lived branches with Gitflow</a>) or shorter pairing sessions for critical parts of the code. We've engaged in remote pairing for years, and we've found it to be effective if done with a dose of pragmatism.</p>"
Simplest possible feature toggle,Adopt,Techniques,TRUE,"<p>Unfortunately, <a href=""https://martinfowler.com/articles/feature-toggles.html"">feature toggles</a> are less common than we'd like, and quite often we see people mixing up its types and use cases. It's quite common to come across teams that use heavyweight platforms such as <a href=""https://launchdarkly.com/"">LaunchDarkly</a> to implement feature toggles, including release toggles, to benefit from <a href=""https://martinfowler.com/articles/continuousIntegration.html"">Continuous Integration</a>, when all you need are if/else conditionals. Therefore, unless you need A/B testing or <a href=""https://martinfowler.com/bliki/CanaryRelease.html"">canary release</a> or hand over feature release responsibility to business folks, we encourage you to use the <strong>simplest possible feature toggle</strong> instead of unnecessarily complex feature toggle frameworks.</p>"
Continuous delivery for machine learning (CD4ML),Trial,Techniques,FALSE,"<p>Applying machine learning to make the business applications and services intelligent is more than just training models and serving them. It requires implementing end-to-end and continuously repeatable cycles of training, testing, deploying, monitoring and operating the models. <strong><a href=""https://martinfowler.com/articles/cd4ml.html"">Continuous delivery for machine learning (CD4ML)</a></strong> is a technique that enables reliable end-to-end cycles of development, deploying and monitoring machine learning models. The underpinning technology stack to enable CD4ML includes tooling for accessing and discovering data, version control of artefacts (such as data, model and code), continuous delivery pipelines, automated environment provisioning for various deployments and experiments, model performance assessment and tracking, and model operational observability. Companies can choose their own tool set depending on their existing tech stack. CD4ML emphasizes automation and removing manual handoffs. CD4ML is our de facto approach for developing ML models.</p>"
Ethical bias testing,Trial,Techniques,FALSE,"<p>Over the past year, we've seen a shift in interest around machine learning and deep neural networks in particular. Until now, tool and technique development has been driven by excitement over the remarkable capabilities of these models. Currently, though, there is rising concern that these models could cause unintentional harm. For example, a model could be trained inadvertently to make profitable credit decisions by simply excluding disadvantaged applicants. Fortunately, we're seeing a growing interest in <strong>ethical bias testing</strong> that will help to uncover potentially harmful decisions. Tools such as <a href=""https://github.com/marcotcr/lime"">lime</a>, <a href=""https://aif360.mybluemix.net/"">AI Fairness 360</a> or <a href=""/radar/tools/what-if-tool"">What-If Tool</a> can help uncover inaccuracies that result from underrepresented groups in training data and visualization tools such as <a href=""https://ai.googleblog.com/2017/07/facets-open-source-visualization-tool.html"">Google Facets</a> or <a href=""https://pair-code.github.io/facets/"">Facets Dive</a> can be used to discover subgroups within a corpus of training data. We've used lime (local interpretable model-agnostic explanations) in addition to this technique in order to understand the predictions of any machine-learning classifier and what classifiers (or models) are doing.</p>"
GraphQL for server-side resource aggregation,Trial,Techniques,FALSE,"<p>We see more and more tools such as <a href=""https://www.apollographql.com/docs/apollo-server/federation/introduction/"">Apollo Federation</a> that can aggregate multiple GraphQL endpoints into a single graph. However, we caution against misusing <a href=""/radar/languages-and-frameworks/graphql"">GraphQL</a>, especially when turning it into a server-to-server protocol. Our practice is to use <strong><a href=""/radar/techniques/graphql-for-server-side-resource-aggregation"">GraphQL for server-side resource aggregation</a></strong> only. When using this pattern, the microservices continue to expose well-defined RESTful APIs, while under-the-hood aggregate services or <a href=""/radar/techniques/bff-backend-for-frontends"">BFF (Backend for Frontends)</a> patterns use GraphQL resolvers as the implementation for stitching resources from other services. The shape of the graph is driven by domain-modeling exercises to ensure ubiquitous language is limited to subgraphs where needed (in the case of one-microservice-per-bounded-context). This technique simplifies the internal implementation of aggregate services or BFFs, while encouraging good modeling of services to avoid <a href=""/radar/techniques/anemic-rest"">anemic REST</a>.</p>"
Micro frontends for mobile,Trial,Techniques,TRUE,"<p>Since introducing it in the Radar in 2016, we've seen widespread adoption of <a href=""/radar/techniques/micro-frontends"">micro frontends</a> for web UIs. Recently, however, we've seen projects extend this architectural style to include <strong>micro frontends for mobile</strong> applications as well. When the application becomes sufficiently large and complex, it becomes necessary to distribute the development over multiple teams. This presents the challenge of maintaining team autonomy while integrating their work into a single app. Although we've seen teams writing their own frameworks to enable this development style, existing modularization frameworks such as <a href=""/radar/languages-and-frameworks/atlas-and-beehive"">Atlas and Beehive</a> can also simplify the problem of integrating multiteam app development.</p>"
Platform engineering product teams,Trial,Techniques,FALSE,"<p>The adoption of cloud and DevOps — while increasing the productivity of teams who can now move more quickly with reduced dependency on centralized operations teams and infrastructure — also has constrained teams that lack the skills to self-manage a full application and operations stack. Some organizations have tackled this challenge by creating <strong>platform engineering product teams</strong>. These teams maintain an internal platform that enables delivery teams to deploy and operate systems with reduced lead time and stack complexity. The emphasis here is on API-driven self-service and supporting tools, with delivery teams still responsible for supporting what they deploy onto the platform. Organizations that consider establishing such a platform team should be very cautious not to accidentally create a <a href=""/radar/techniques/separate-devops-team"">separate DevOps team</a>, nor should they simply relabel their <a href=""/radar/platforms/superficial-private-cloud"">existing hosting and operations structure</a> as a platform. If you're wondering how to best set up platform teams, we've been using the concepts from <a href=""https://teamtopologies.com/"">Team Topologies</a> to split platform teams in our projects into enablement teams, core ""platform within a platform"" teams and stream-focused teams.</p>"
Security policy as code,Trial,Techniques,FALSE,"<p>Security policies are rules and procedures that protect our systems from threats and disruption. For example, access control policies define and enforce who can access which services and resources under what circumstances; or network security policies can dynamically limit the traffic rate to a particular service. The complexity of the technology landscape today demands treating <strong>security policy as code</strong>: define and keep policies under version control, automatically validate them, automatically deploy them and monitor their performance. Tools such as <a href=""/radar/tools/open-policy-agent-opa"">Open Policy Agent</a> or platforms such as <a href=""/radar/platforms/istio"">Istio</a> provide flexible policy definition and enforcement mechanisms that support the practice of security policy as code.</p>"
Semi-supervised learning loops,Trial,Techniques,FALSE,"<p><strong>Semi-supervised learning loops</strong> are a class of iterative machine-learning workflows that take advantage of the relationships to be found in unlabeled data. These techniques may improve models by combining labeled and unlabeled data sets in various ways. In other cases they compare models trained on different subsets of the data. Unlike either unsupervised learning where a machine infers classes in unlabeled data or supervised techniques where the training set is entirely labeled, semi-supervised techniques take advantage of a small set of labeled data and a much larger set of unlabeled data. Semi-supervised learning is also closely related to active learning techniques where a human is directed to selectively label ambiguous data points. Since expert humans that can accurately label data are a scarce resource and labeling is often the most time-consuming activity in the machine-learning workflow, semi-supervised techniques lower the cost of training and make machine learning feasible for a new class of users. We're also seeing the application of weakly supervised techniques where machine-labeled data is used but is trusted less than the data labeled by humans.</p>"
Transfer learning for NLP,Trial,Techniques,FALSE,"<p>We had this technique in Assess previously. The innovations in the NLP landscape continue at a great pace, and we're able to leverage these innovations in our projects thanks to the ubiquitous <strong>transfer learning for NLP</strong>. The GLUE benchmark (a suite of language understanding tasks) scores have seen dramatic progress over the past couple of years with average scores moving from 70.0 at launch to some of the leaders crossing 90.0 as of April 2020. A lot of our projects in the NLP domain are able to make significant progress by starting from pretrained models from ELMo, <a href=""/radar/techniques/bert"">BERT</a>, and <a href=""/radar/languages-and-frameworks/ernie"">ERNIE</a>, among others, and then fine-tuning them based on the project needs.</p>"
"Use ""remote native"" processes and approaches",Trial,Techniques,TRUE,"<p><a href=""https://www.martinfowler.com/articles/remote-or-co-located.html"">Distributed teams come in many shapes and setups</a>; delivery teams in a 100% single-site co-located setup, however, have become the exception for us. Most of our teams are either multisite teams or have at least some team members working off-site. Therefore, <strong>using ""remote native"" processes and approaches</strong> by default can help significantly with the overall team flow and effectiveness. This starts with making sure that everybody has access to the necessary remote systems. Moreover, using tools such as <a href=""/radar/tools/visual-studio-live-share"">Visual Studio Live Share</a>, <a href=""/radar/tools/mural"">MURAL</a> or <a href=""https://gsuite.google.com/products/jamboard/"">Jamboard</a> turn online workshops and remote pairing into routines instead of ineffective exceptions. But ""remote native"" goes beyond a lift-and-shift of co-location practices to the digital world: Embracing more asynchronous communication, even more discipline around decision documentation, and ""everybody always remote"" meetings are other approaches our teams practice by default to optimize for location fluidity.</p>"
Zero trust architecture (ZTA),Trial,Techniques,TRUE,"<p>The technology landscape of organizations today is increasingly more complex with assets — data, functions, infrastructure and users — spread across security boundaries, such as local hosts, multiple cloud providers and a variety of SaaS vendors. This demands a paradigm shift in enterprise security planning and systems architecture, moving from static and slow-changing security policy management, based on trust zones and network configurations, to dynamic, fine-grained security policy enforcement based on temporal access privileges.</p>
